一、技术架构
（一）开发环境
编程语言：Python 3.x
主要库 / 框架：
requests：用于发送 HTTP 请求，获取网页源代码。
lxml：基于 XPath 解析 HTML 页面，提取书籍信息。
pandas：用于数据清洗、整理及 CSV 文件存储。
time：控制请求频率，避免对目标网站造成过大压力。
（二）文件结构
文件名	功能描述
Get_html.py	封装网页请求逻辑，包含请求头设置、异常处理及 HTML 内容获取。
Parse_html.py	实现 HTML 内容解析，使用 XPath 提取书籍标题、作者、评分等信息，并处理数据格式。
Save_to_CSV.py	负责将解析后的数据存储为 CSV 文件，确保数据持久化。
main.py	主程序入口，协调各模块运行，控制爬取流程（如分页处理、休眠机制）。
douban_books_top250.csv	存储爬取结果的 CSV 文件，包含 250 条书籍信息。
三、核心功能
（一）网页爬取
请求策略：模拟浏览器行为，设置User-Agent请求头，避免被网站识别为爬虫。
分页处理：通过 URL 参数start实现分页爬取（如https://book.douban.com/top250?start=25），循环 10 次获取全部 250 条数据。
异常处理：使用try-except捕获请求过程中的异常（如网络超时、连接错误），确保程序健壮性。
（二）数据解析
信息提取：通过 XPath 表达式从 HTML 中提取关键信息：
书名：//div[@class="pl2"]/a/text()
作者 / 译者 / 出版社：//p[@class="pl"]/text()（通过/分割并清洗）
评分：//span[@class="rating_nums"]/text()
评价人数：//span[@class="pl"]/text()（需去除无关字符）
一句话评价：//span[@class="inq"]/text()
数据清洗：处理作者信息中的国籍（如[美] 傅高义），拆分多字段信息（如价格、出版日期），补全缺失值（如无译者时设为空字符串）。
（三）数据存储
格式转换：将解析后的字典列表转换为pandas.DataFrame格式，便于结构化处理。
文件保存：使用to_csv方法将数据存储为 CSV 文件，指定编码为utf-8-sig以解决中文乱码问题，并添加 BOM 标记。
四、运行流程
启动主程序：main.py初始化数据列表，遍历 10 个分页 URL。
获取 HTML：调用Get_html.py中的get_html函数，获取每页网页内容。
解析数据：通过Parse_html.py的parse_html函数解析 HTML，返回书籍信息列表。
数据累加：将每页解析结果添加到总列表，避免内存溢出。
休眠机制：每页爬取后休眠 1 秒，遵守网站爬取规则，降低封禁风险。
保存结果：爬取完成后，调用Save_to_CSV.py将数据写入 CSV 文件，并输出保存路径。
五、数据说明
（一）字段描述
字段名	类型	说明	示例
书名	字符串	书籍全称	《红楼梦》
豆瓣链接	字符串	书籍在豆瓣的详情页 URL	https://book.douban.com/subject/1007305/
作者	字符串	作者姓名（可能包含国籍）	曹雪芹 著、[美] 傅高义 (Ezra.F.Vogel)
译者	字符串	译者姓名（无译者时为空）	苏农、冯克利
出版社	字符串	书籍出版机构	人民文学出版社
出版日期	字符串	出版时间	1996-12
价格	字符串	书籍定价	59.70 元
评分	字符串	豆瓣评分（满分 10 分）	9.7
评分人数	字符串	参与评分的人数	(444603 人评价)
一句话评价	字符串	豆瓣推荐的短评	都云作者痴，谁解其中味？
（二）数据示例
书名	豆瓣链接	作者	译者	出版社	出版日期	价格	评分	评分人数	一句话评价
《活着》	https://book.douban.com/subject/4913064/	余华		作家出版社
